{
  "metadata" : {
    "id" : "d59b0b75-78c2-4f6f-b808-988c3ed021f4",
    "name" : "continuous-processing-anomaly-detection",
    "user_save_timestamp" : "1969-12-31T19:00:00.000Z",
    "auto_save_timestamp" : "1969-12-31T19:00:00.000Z",
    "language_info" : {
      "name" : "scala",
      "file_extension" : "scala",
      "codemirror_mode" : "text/x-scala"
    },
    "trusted" : true,
    "sparkNotebook" : null,
    "customLocalRepo" : null,
    "customRepos" : null,
    "customDeps" : [ "org.apache.spark %% spark-sql-kafka-0-10 % 2.3.0" ],
    "customImports" : null,
    "customArgs" : null,
    "customSparkConf" : null,
    "customVars" : null
  },
  "cells" : [ {
    "metadata" : {
      "id" : "CE89CE47AA7D417581D75EA6E34A6CFD"
    },
    "cell_type" : "markdown",
    "source" : "#Real-Time Anomaly Detection Using Continuous Processing\nThis notebook uses the exported M2 Model by Spark Streaming and combines it with a Continuous Processing job in Structured Streaming to deliver real-time anomaly detection on the raw data stream."
  }, {
    "metadata" : {
      "id" : "92D6258DD425441388775107922BAF05"
    },
    "cell_type" : "markdown",
    "source" : "## Common settings"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "7868577A32F048309DE0AD504C46624C"
    },
    "cell_type" : "code",
    "source" : [ "val topic = \"sensor-raw\"\n", "val kafkaBootstrapServer = \"172.17.0.2:9092\"\n", "val threshold = 4.0\n", "val targetDir = \"/tmp/anomaly/model\"" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "topic: String = sensor-raw\nkafkaBootstrapServer: String = 172.17.0.2:9092\nthreshold: Double = 4.0\ntargetDir: String = /tmp/anomaly/model\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 1,
      "time" : "Took: 1.723s, at 2018-09-12 00:20"
    } ]
  }, {
    "metadata" : {
      "id" : "B9735AAD3FC24F5887D6FD461A33C520"
    },
    "cell_type" : "markdown",
    "source" : "## We locate the most recent model in the target directory"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "presentation" : {
        "tabs_state" : "{\n  \"tab_id\": \"#tab1949881828-0\"\n}",
        "pivot_chart_state" : "{\n  \"hiddenAttributes\": [],\n  \"menuLimit\": 200,\n  \"cols\": [],\n  \"rows\": [],\n  \"vals\": [],\n  \"exclusions\": {},\n  \"inclusions\": {},\n  \"unusedAttrsVertical\": 85,\n  \"autoSortUnusedAttrs\": false,\n  \"inclusionsInfo\": {},\n  \"aggregatorName\": \"Count\",\n  \"rendererName\": \"Table\"\n}"
      },
      "id" : "31FFCE65A5BB49AC9C9250C8EF353E30"
    },
    "cell_type" : "code",
    "source" : [ "import java.io.File\n", "import scala.collection.JavaConverters._\n", "val availableFiles = new File(targetDir).listFiles.map(_.getName).filter(_.endsWith(\".json\"))\n", "val mostRecent = availableFiles.sortBy{f => \n", "                   val timestamp = f.split(\"-\").last.dropRight(\".json\".length)\n", "                   -timestamp.toLong\n", "                  }.head\n" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "import java.io.File\nimport scala.collection.JavaConverters._\navailableFiles: Array[String] = Array(sensors-m2-1536725530000.json, sensors-m2-1536724670000.json, sensors-m2-1536723670000.json, sensors-m2-1536725890000.json, sensors-m2-1536722670000.json, sensors-m2-1536722560000.json, sensors-m2-1536723280000.json, sensors-m2-1536722920000.json, sensors-m2-1536725720000.json, sensors-m2-1536723470000.json, sensors-m2-1536725970000.json, sensors-m2-1536724500000.json, sensors-m2-1536723720000.json, sensors-m2-1536725860000.json, sensors-m2-1536723020000.json, sensors-m2-1536724860000.json, sensors-m2-1536724510000.json, sensors-m2-1536724080000.json, sensors-m2-1536725040000.json, sensors-m2-1536723340000.json, sensors-m2-1536722820000.json, sensors-m2-1536723110000.json, sensors-m2-15367..."
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 2,
      "time" : "Took: 1.875s, at 2018-09-12 00:20"
    } ]
  }, {
    "metadata" : {
      "id" : "9391BBE443D0446E89FCA4FA1E27B6B5"
    },
    "cell_type" : "markdown",
    "source" : "## Case class and Schema definitions"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "4E05EEA1D7A742DA9DABBF7832C645AB"
    },
    "cell_type" : "code",
    "source" : [ "case class M2(n:Int, mean: Double, m2:Double) {\n", "  def variance: Option[Double] = {\n", "    if (n<2) None else Some(m2/(n-1))\n", "  }\n", "  def stdev: Option[Double] = variance.map(Math.sqrt)\n", "}\n", "case class IdM2(id:String, m2: M2)\n", "case class SensorData(id: String, ts: Long, temp: Double, hum: Double)" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "defined class M2\ndefined class IdM2\ndefined class SensorData\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 3,
      "time" : "Took: 1.829s, at 2018-09-12 00:20"
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "31FBD06486E649468601F19E237E1375"
    },
    "cell_type" : "code",
    "source" : [ "import org.apache.spark.sql.Encoders\n", "val idM2Schema = Encoders.product[IdM2].schema\n", "val sensorSchema = Encoders.product[SensorData].schema" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "import org.apache.spark.sql.Encoders\nidM2Schema: org.apache.spark.sql.types.StructType = StructType(StructField(id,StringType,true), StructField(m2,StructType(StructField(n,IntegerType,false), StructField(mean,DoubleType,false), StructField(m2,DoubleType,false)),true))\nsensorSchema: org.apache.spark.sql.types.StructType = StructType(StructField(id,StringType,true), StructField(ts,LongType,false), StructField(temp,DoubleType,false), StructField(hum,DoubleType,false))\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 4,
      "time" : "Took: 2.696s, at 2018-09-12 00:20"
    } ]
  }, {
    "metadata" : {
      "id" : "D31AABFB4BA644A2A52632A97B95DCB9"
    },
    "cell_type" : "markdown",
    "source" : "## Parse the JSON Data"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "C2E1048DF8414A5797CE2357CC631C5F"
    },
    "cell_type" : "code",
    "source" : [ "val mostRecentM2JsonModel = sparkSession.read.schema(idM2Schema).json(s\"$targetDir/$mostRecent\").as[IdM2]\n" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "mostRecentM2JsonModel: org.apache.spark.sql.Dataset[IdM2] = [id: string, m2: struct<n: int, mean: double ... 1 more field>]\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 5,
      "time" : "Took: 3.556s, at 2018-09-12 00:20"
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "presentation" : {
        "tabs_state" : "{\n  \"tab_id\": \"#tab1586006337-0\"\n}",
        "pivot_chart_state" : "{\n  \"hiddenAttributes\": [],\n  \"menuLimit\": 200,\n  \"cols\": [],\n  \"rows\": [],\n  \"vals\": [],\n  \"exclusions\": {},\n  \"inclusions\": {},\n  \"unusedAttrsVertical\": 85,\n  \"autoSortUnusedAttrs\": false,\n  \"inclusionsInfo\": {},\n  \"aggregatorName\": \"Count\",\n  \"rendererName\": \"Table\"\n}"
      },
      "id" : "78637D7C877B4C9EB166477FF4839A5F"
    },
    "cell_type" : "code",
    "source" : [ "val m2Map = mostRecentM2JsonModel.collect.map(idM2=> (idM2.id, idM2.m2)).toMap" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "m2Map: scala.collection.immutable.Map[String,M2] = Map(sim-614 -> M2(373,22.347265415549593,123.51141072386125), sim-183 -> M2(373,22.398713136729228,104.37838230562983), sim-129 -> M2(373,22.61804289544236,156.14367131367314), sim-486 -> M2(373,26.232922252010734,505.6961147453083), sim-189 -> M2(373,10.730911528150138,174.89929008042895), sim-352 -> M2(373,13.18957104557641,86.40493136729171), sim-674 -> M2(373,28.456005361930302,460.75154798927633), sim-358 -> M2(373,22.31747989276138,106.62643109919601), sim-392 -> M2(373,22.57742627345844,111.48352922252042), sim-849 -> M2(373,22.750723860589794,107.1187045576406), sim-178 -> M2(373,23.37080428954424,184.38375871313767), sim-875 -> M2(373,13.945040214477206,95.99332439678311), sim-516 -> M2(373,22.43932975871313,107.5289324396787),..."
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 6,
      "time" : "Took: 3.786s, at 2018-09-12 00:20"
    } ]
  }, {
    "metadata" : {
      "id" : "BBB21A0011E14F7F89B017D8BAAD0CC4"
    },
    "cell_type" : "markdown",
    "source" : "## Read the Raw Stream from Kafka"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "D681695818F146B79C827C8081A6ED4D"
    },
    "cell_type" : "code",
    "source" : [ "val rawData = sparkSession.readStream\n", "      .format(\"kafka\")\n", "      .option(\"kafka.bootstrap.servers\", kafkaBootstrapServer)\n", "      .option(\"subscribe\", topic)\n", "      .option(\"startingOffsets\", \"latest\")\n", "      .load()" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "rawData: org.apache.spark.sql.DataFrame = [key: binary, value: binary ... 5 more fields]\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 7,
      "time" : "Took: 1.455s, at 2018-09-12 00:20"
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "39E1CF9668D343819F3C979874A6B2D8"
    },
    "cell_type" : "code",
    "source" : [ "val rawValues = rawData.selectExpr(\"CAST(value AS STRING)\").as[String]\n", "val jsonValues = rawValues.select(from_json($\"value\", sensorSchema) as \"record\")\n", "val sensorData = jsonValues.select(\"record.*\").as[SensorData]" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "rawValues: org.apache.spark.sql.Dataset[String] = [value: string]\njsonValues: org.apache.spark.sql.DataFrame = [record: struct<id: string, ts: bigint ... 2 more fields>]\nsensorData: org.apache.spark.sql.Dataset[SensorData] = [id: string, ts: bigint ... 2 more fields]\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 8,
      "time" : "Took: 1.853s, at 2018-09-12 00:20"
    } ]
  }, {
    "metadata" : {
      "id" : "A5FAB1BBB48045338CE02A807B218BF9"
    },
    "cell_type" : "markdown",
    "source" : "## Apply the scoring process"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "F3C88CAC1F604D8081012082ECB28122"
    },
    "cell_type" : "code",
    "source" : [ "val scoreStream = sensorData.flatMap{case SensorData(id, ts, temp, hum) => \n", "                                     val m2Opt = m2Map.get(id)\n", "                                     m2Opt.map{m2 => (id, ts, temp, m2.mean, m2.stdev)}\n", "                                    }.toDF(\"id\", \"ts\",\"temp\",\"mean\",\"std\")\n", "                                 " ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "scoreStream: org.apache.spark.sql.DataFrame = [id: string, ts: bigint ... 3 more fields]\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 9,
      "time" : "Took: 1.494s, at 2018-09-12 00:20"
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "3D92FF17C43B425E90BABFD505358967"
    },
    "cell_type" : "code",
    "source" : [ "import org.apache.spark.sql.functions._\n", "val suspects = scoreStream.where($\"temp\" > $\"mean\"+$\"std\"*threshold or $\"temp\" < $\"mean\"-$\"std\"*threshold)" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "import org.apache.spark.sql.functions._\nsuspects: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [id: string, ts: bigint ... 3 more fields]\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 10,
      "time" : "Took: 1.313s, at 2018-09-12 00:20"
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "21245E343B1D42A1B7675D4B66B99B0C"
    },
    "cell_type" : "code",
    "source" : [ "import org.apache.spark.sql.streaming.Trigger\n", "val query = suspects.writeStream\n", "                    .format(\"memory\")\n", "                    .queryName(\"continuousStreamDetection\")\n", "                    .trigger(Trigger.Continuous(\"1 second\"))\n", "                    .start() " ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "import org.apache.spark.sql.streaming.Trigger\nquery: org.apache.spark.sql.streaming.StreamingQuery = org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@6b8ed1e6\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 59,
      "time" : "Took: 1.079s, at 2018-09-12 00:35"
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "28B9D372DC66468B976A4CBF3B02BEF2"
    },
    "cell_type" : "code",
    "source" : [ "query.stop" ],
    "outputs" : [ {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 58,
      "time" : "Took: 1.295s, at 2018-09-12 00:35"
    } ]
  }, {
    "metadata" : {
      "id" : "4CC61893D0C44D1FAAA3BCFF019426E3"
    },
    "cell_type" : "markdown",
    "source" : "## Let's do some Visualization"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "9DE102EBB974485EB8C014F85A14AC7A"
    },
    "cell_type" : "code",
    "source" : [ "val dummy = Seq((\"id\", 0.0))\n", "\n", "val chart = CustomPlotlyChart(dummy,\n", "                  layout=s\"{title: 'sensor anomaly indicator'}\",\n", "                  dataOptions=\"\"\"{type: 'bar'}\"\"\",\n", "                  dataSources=\"{x: '_1', y: '_2' }\")\n", "chart" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "dummy: Seq[(String, Double)] = List((id,0.0))\nchart: notebook.front.widgets.charts.CustomPlotlyChart[Seq[(String, Double)]] = <CustomPlotlyChart widget>\nres12: notebook.front.widgets.charts.CustomPlotlyChart[Seq[(String, Double)]] = <CustomPlotlyChart widget>\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : "<div>\n      <script data-this=\"{&quot;dataId&quot;:&quot;anon50b271925d53aa7f2e5f6f60cc173fc1&quot;,&quot;dataInit&quot;:[{&quot;_1&quot;:&quot;id&quot;,&quot;_2&quot;:0}],&quot;genId&quot;:&quot;1390368987&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/playground','../javascripts/notebook/magic/customPlotlyChart'], \n      function(playground, _magiccustomPlotlyChart) {\n        // data ==> data-this (in observable.js's scopedEval) ==> this in JS => { dataId, dataInit, ... }\n        // this ==> scope (in observable.js's scopedEval) ==> this.parentElement ==> div.container below (toHtml)\n\n        playground.call(data,\n                        this\n                        ,\n                        {\n    \"f\": _magiccustomPlotlyChart,\n    \"o\": {\"js\":\"var layout = {title: 'sensor anomaly indicator'}; var dataSources={x: '_1', y: '_2' }; var dataOptions = {type: 'bar'}; var extraOptions = {}\",\"headers\":[\"_1\",\"_2\"],\"height\":400}\n  }\n  \n                        \n                        \n                      );\n      }\n    );/*]]>*/</script>\n    <div>\n      <span class=\"chart-total-item-count\"><p data-bind=\"text: value\"><script data-this=\"{&quot;valueId&quot;:&quot;anon23b24ddd260a20b505650246d6265368&quot;,&quot;initialValue&quot;:&quot;1&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/\nreq(\n['observable', 'knockout'],\nfunction (O, ko) {\n  ko.applyBindings({\n      value: O.makeObservable(valueId, initialValue)\n    },\n    this\n  );\n});\n        /*]]>*/</script></p> entries total</span>\n      <span class=\"chart-sampling-warning\"><p data-bind=\"text: value\"><script data-this=\"{&quot;valueId&quot;:&quot;anonf91e50798e90bb4e980a045285c6102b&quot;,&quot;initialValue&quot;:&quot;&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/\nreq(\n['observable', 'knockout'],\nfunction (O, ko) {\n  ko.applyBindings({\n      value: O.makeObservable(valueId, initialValue)\n    },\n    this\n  );\n});\n        /*]]>*/</script></p></span>\n      <div>\n      </div>\n    </div></div>"
      },
      "output_type" : "execute_result",
      "execution_count" : 12,
      "time" : "Took: 2.071s, at 2018-09-12 00:20"
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "C2AB56A90497432E8CA7F54643BC64E3"
    },
    "cell_type" : "code",
    "source" : [ "@volatile var running = true" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "running: Boolean = true\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 90,
      "time" : "Took: 0.915s, at 2018-09-12 00:39"
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "2370A21BFEB449AA8E179F1711F65F7A"
    },
    "cell_type" : "code",
    "source" : [ "import scala.concurrent.duration._\n", "import scala.annotation.tailrec\n", "\n", "val updater = new Thread() {\n", "  @tailrec\n", "  def visualize(): Unit = {\n", "    val currentTimeThreshold = System.currentTimeMillis - 5*1000\n", "    val data = sparkSession.sql(s\"select id, temp from continuousStreamDetection where ts > $currentTimeThreshold\")\n", "                           .as[(String, Double)]\n", "                           .collect\n", "    if (data.nonEmpty) chart.applyOn(data)\n", "    if (running) {\n", "      Thread.sleep(1.second.toMillis)\n", "      visualize()\n", "    } else ()\n", "  } \n", "  \n", "  override def run() {\n", "    visualize()\n", "  }\n", "}.start()\n" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "import scala.concurrent.duration._\nimport scala.annotation.tailrec\nupdater: Unit = ()\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 92,
      "time" : "Took: 1.320s, at 2018-09-12 00:39"
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "949C3CC7C314434984FCF83588819EE5"
    },
    "cell_type" : "code",
    "source" : [ "// execute to stop the chart updating thread\n", "running = false" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "running: Boolean = false\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 94,
      "time" : "Took: 1.093s, at 2018-09-12 00:43"
    } ]
  }, {
    "metadata" : {
      "id" : "73CC98AACACD41848CC0F78478C5C03B"
    },
    "cell_type" : "markdown",
    "source" : "# -- o --"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "presentation" : {
        "tabs_state" : "{\n  \"tab_id\": \"#tab2113607371-0\"\n}",
        "pivot_chart_state" : "{\n  \"hiddenAttributes\": [],\n  \"menuLimit\": 200,\n  \"cols\": [],\n  \"rows\": [],\n  \"vals\": [],\n  \"exclusions\": {},\n  \"inclusions\": {},\n  \"unusedAttrsVertical\": 85,\n  \"autoSortUnusedAttrs\": false,\n  \"inclusionsInfo\": {},\n  \"aggregatorName\": \"Count\",\n  \"rendererName\": \"Table\"\n}"
      },
      "id" : "76A730A3B6DA45B58D350EBE86C260EF"
    },
    "cell_type" : "code",
    "source" : [ "memTable.where($\"id\" === \"office\")" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "res150: org.apache.spark.sql.Dataset[(String, Long, Double)] = [id: string, ts: bigint ... 1 more field]\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : "<div class=\"df-canvas\">\n      <script data-this=\"{&quot;dataId&quot;:&quot;anon647819b1833202a2f70aeb0d3396743a&quot;,&quot;partitionIndexId&quot;:&quot;anon7291e2f670ae487b2e46f91e98d62005&quot;,&quot;numPartitions&quot;:9,&quot;dfSchema&quot;:{&quot;type&quot;:&quot;struct&quot;,&quot;fields&quot;:[{&quot;name&quot;:&quot;id&quot;,&quot;type&quot;:&quot;string&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;ts&quot;,&quot;type&quot;:&quot;long&quot;,&quot;nullable&quot;:false,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;temp&quot;,&quot;type&quot;:&quot;double&quot;,&quot;nullable&quot;:false,&quot;metadata&quot;:{}}]}}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/dataframe','../javascripts/notebook/consoleDir'], \n      function(dataframe, extension) {\n        dataframe.call(data, this, extension);\n      }\n    );/*]]>*/</script>\n      <link rel=\"stylesheet\" href=\"/assets/stylesheets/ipython/css/dataframe.css\" type=\"text/css\"/>\n    </div>"
      },
      "output_type" : "execute_result",
      "execution_count" : 93,
      "time" : "Took: 1.653s, at 2018-09-12 00:40"
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true,
      "id" : "8C79874D846F4EA8849475E6C16BA620"
    },
    "cell_type" : "code",
    "source" : [ "" ],
    "outputs" : [ ]
  } ],
  "nbformat" : 4
}