{
  "metadata" : {
    "id" : "7676e4a4-9d4d-4ee6-b367-1d88b5a139d6",
    "name" : "4b-anomaly-visualization.snb.ipynb",
    "user_save_timestamp" : "2018-12-06T16:07:57.008Z",
    "auto_save_timestamp" : "1970-01-01T01:00:00.000Z",
    "language_info" : {
      "name" : "scala",
      "file_extension" : "scala",
      "codemirror_mode" : "text/x-scala"
    },
    "trusted" : true,
    "sparkNotebook" : null,
    "customLocalRepo" : null,
    "customRepos" : null,
    "customDeps" : [ "org.apache.spark %% spark-sql-kafka-0-10 % 2.3.0" ],
    "customImports" : null,
    "customArgs" : null,
    "customSparkConf" : null,
    "customVars" : null
  },
  "cells" : [ {
    "metadata" : {
      "id" : "7250AA69DA694086874701C00607F57F"
    },
    "cell_type" : "markdown",
    "source" : "\n#Anomaly Detection Visualization\nIn this notebook, we consume the anomaly detection topic to display the potentially anomalous sensors."
  }, {
    "metadata" : {
      "id" : "D136FC8F2E8946C087AFB65BF48B1C7E"
    },
    "cell_type" : "markdown",
    "source" : "## Common settings"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "6BD229C77DBE4A8B882752A4D1F5EB6B"
    },
    "cell_type" : "code",
    "source" : [ "import org.apache.spark.streaming.Seconds\n", "\n", "val topic = \"sensor-raw\"\n", "val modelTopic = \"modelTopic\"\n", "val anomalyTopic = \"anomalyTopic\"\n", "val kafkaBootstrapServer = \"172.17.0.2:9092\"\n", "val threshold = 4.0 // 5% failure rate\n", "val modelRefreshInterval = Seconds(30)" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "import org.apache.spark.streaming.Seconds\ntopic: String = sensor-raw\nmodelTopic: String = modelTopic\nanomalyTopic: String = anomalyTopic\nkafkaBootstrapServer: String = 172.17.0.2:9092\nthreshold: Double = 4.0\nmodelRefreshInterval: org.apache.spark.streaming.Duration = 30000 ms\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 1,
      "time" : "Took: 2.337s, at 2018-12-06 16:08"
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "3BFDFB8513FE4EA4848154AEFC8B05CB"
    },
    "cell_type" : "code",
    "source" : [ "val anomalyDataStream = sparkSession.readStream\n", "      .format(\"kafka\")\n", "      .option(\"kafka.bootstrap.servers\", kafkaBootstrapServer)\n", "      .option(\"subscribe\", anomalyTopic)\n", "      .option(\"startingOffsets\", \"latest\")\n", "      .load()" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "anomalyDataStream: org.apache.spark.sql.DataFrame = [key: binary, value: binary ... 5 more fields]\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 2,
      "time" : "Took: 2.950s, at 2018-12-06 15:42"
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "D19085E02C664FCC85FCCDBB128472D2"
    },
    "cell_type" : "code",
    "source" : [ "case class AnomalyReport(id: String, ts: Long, value: Double, stdev: Double)\n", "import org.apache.spark.sql.Encoders\n", "val schema = Encoders.product[AnomalyReport].schema" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "defined class AnomalyReport\nimport org.apache.spark.sql.Encoders\nschema: org.apache.spark.sql.types.StructType = StructType(StructField(id,StringType,true), StructField(ts,LongType,false), StructField(value,DoubleType,false), StructField(stdev,DoubleType,false))\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 3,
      "time" : "Took: 2.156s, at 2018-12-06 15:42"
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "99F533F24C154EFC8F43AF29957415BA"
    },
    "cell_type" : "code",
    "source" : [ "val rawValues = anomalyDataStream.selectExpr(\"CAST(value AS STRING)\").as[String]\n", "val jsonValues = rawValues.select(from_json($\"value\", schema) as \"record\")\n", "val anomalyData = jsonValues.select(\"record.*\").as[AnomalyReport]" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "rawValues: org.apache.spark.sql.Dataset[String] = [value: string]\njsonValues: org.apache.spark.sql.DataFrame = [record: struct<id: string, ts: bigint ... 2 more fields>]\nanomalyData: org.apache.spark.sql.Dataset[AnomalyReport] = [id: string, ts: bigint ... 2 more fields]\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 4,
      "time" : "Took: 2.559s, at 2018-12-06 15:43"
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "877C6C5585CB4AE9878104C3FBFA2A29"
    },
    "cell_type" : "code",
    "source" : [ "val memQuery = anomalyData.writeStream\n", "           .format(\"memory\")\n", "           .queryName(\"anomalyMemReport\")\n", "           .outputMode(\"append\")\n", "           .start()" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "memQuery: org.apache.spark.sql.streaming.StreamingQuery = org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@ff26c82\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 5,
      "time" : "Took: 1.810s, at 2018-12-06 15:43"
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "1C40922B68CB409A84F1EC7A6C78F10C"
    },
    "cell_type" : "code",
    "source" : [ "val anomalyMemData = sparkSession.sql(\"select * from anomalyMemReport\")" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "anomalyMemData: org.apache.spark.sql.DataFrame = [id: string, ts: bigint ... 2 more fields]\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 6,
      "time" : "Took: 1.155s, at 2018-12-06 15:43"
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "78FF7F14E5B84B79A0BDD2609FCFB4C9"
    },
    "cell_type" : "code",
    "source" : [ "anomalyMemData" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "res20: org.apache.spark.sql.DataFrame = [id: string, ts: bigint ... 2 more fields]\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : "<div class=\"df-canvas\">\n      <script data-this=\"{&quot;dataId&quot;:&quot;anon2caa255215e5cf0f7e9f965e4a1ac2a6&quot;,&quot;partitionIndexId&quot;:&quot;anon80bd22ab0cee60279b4741484909090b&quot;,&quot;numPartitions&quot;:6,&quot;dfSchema&quot;:{&quot;type&quot;:&quot;struct&quot;,&quot;fields&quot;:[{&quot;name&quot;:&quot;id&quot;,&quot;type&quot;:&quot;string&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;ts&quot;,&quot;type&quot;:&quot;long&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;value&quot;,&quot;type&quot;:&quot;double&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;stdev&quot;,&quot;type&quot;:&quot;double&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}}]}}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/dataframe','../javascripts/notebook/consoleDir'], \n      function(dataframe, extension) {\n        dataframe.call(data, this, extension);\n      }\n    );/*]]>*/</script>\n      <link rel=\"stylesheet\" href=\"/assets/stylesheets/ipython/css/dataframe.css\" type=\"text/css\"/>\n    </div>"
      },
      "output_type" : "execute_result",
      "execution_count" : 16,
      "time" : "Took: 1.555s, at 2018-12-06 16:01"
    } ]
  }, {
    "metadata" : {
      "id" : "59B5CBD4B7A44A1CB2B0729742565DC7"
    },
    "cell_type" : "markdown",
    "source" : "## Anomalies Chart\nLet's create a chart of the suspected anomalies"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "A6D2CC871C2948439E32B6B672F660FB"
    },
    "cell_type" : "code",
    "source" : [ "case class Bubble(id: String, size: Int, value: Double, pos: Int = 0, color: String = \"red\")" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "defined class Bubble\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 7,
      "time" : "Took: 0.849s, at 2018-12-06 15:43"
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "C8F62406F052451EA6F21C3D8FF49DDE"
    },
    "cell_type" : "code",
    "source" : [ "val bubbles = Seq(Bubble(\"zero\",0, 1, 0, \"black\"), Bubble(\"zero\",1, 1000, 100, \"black\"))\n", "val bubbleChart = CustomPlotlyChart(bubbles, \n", "                  layout=\"{title: 'Anomaly Board', showlegend: false, height: 800, width: 1000}\",\n", "                  dataOptions=\"{mode: 'markers'}\",\n", "                  dataSources=\"{x: 'pos', y: 'value',text: 'id', marker: {size: 'size', color: 'color'}}\")" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "bubbles: Seq[Bubble] = List(Bubble(zero,0,1.0,0,black), Bubble(zero,1,1000.0,100,black))\nbubbleChart: notebook.front.widgets.charts.CustomPlotlyChart[Seq[Bubble]] = <CustomPlotlyChart widget>\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 8,
      "time" : "Took: 1.407s, at 2018-12-06 15:43"
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "6841D81B51C642508CF49DF49D4C4044"
    },
    "cell_type" : "code",
    "source" : [ "@transient var running = true" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "running: Boolean = true\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 18,
      "time" : "Took: 0.980s, at 2018-12-06 16:04"
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "619CA8EDAD2F49C8A0D4F26F603068DD"
    },
    "cell_type" : "code",
    "source" : [ "import org.apache.spark.sql.functions._\n", "import org.apache.spark.sql.types._\n", "import scala.concurrent.duration._\n", "import scala.annotation.tailrec\n", "\n", "val updater = new Thread() {\n", "  @tailrec\n", "  def visualize(): Unit = {\n", "    val lastMinute: Long = System.currentTimeMillis - 1.minute.toMillis\n", "    \n", "    val data = anomalyMemData.select($\"id\",$\"ts\".cast(LongType) as \"timestamp\", $\"value\", $\"stdev\")\n", "                   .where($\"timestamp\" > lastMinute)\n", "                   .orderBy($\"timestamp\")\n", "    val indexedData = data.withColumn(\"pos\", lit(1)).withColumn(\"color\", lit(\"red\"))\n", "                          .withColumn(\"size\", ($\"stdev\"*20+50).cast(IntegerType))\n", "    val bubbleData = indexedData.as[Bubble].collect()\n", "                            .groupBy(_.id)\n", "                            .mapValues(bubbles => bubbles.sortBy(b => -b.size).head)\n", "                            .values\n", "                            .toList\n", "                            .sortBy(_.id)\n", "                            .zipWithIndex\n", "                            .map{case (bubble,idx) => bubble.copy(pos=idx)}\n", "    \n", "    if (bubbleData.nonEmpty) bubbleChart.applyOn(bubbleData)\n", "    if (running) {\n", "      Thread.sleep(1.second.toMillis)\n", "      visualize()\n", "    } else ()\n", "  } \n", "  \n", "  override def run() {\n", "    visualize()\n", "  }\n", "}.start()\n" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "import org.apache.spark.sql.functions._\nimport org.apache.spark.sql.types._\nimport scala.concurrent.duration._\nimport scala.annotation.tailrec\nupdater: Unit = ()\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 19,
      "time" : "Took: 1.701s, at 2018-12-06 16:04"
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "90231946723D48718704724FB6C53F79"
    },
    "cell_type" : "code",
    "source" : [ "bubbleChart" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "res12: notebook.front.widgets.charts.CustomPlotlyChart[Seq[Bubble]] = <CustomPlotlyChart widget>\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : "<div>\n      <script data-this=\"{&quot;dataId&quot;:&quot;anon354b0bbd5dcb61cba48bc6bd0ff07238&quot;,&quot;dataInit&quot;:[{&quot;size&quot;:0,&quot;pos&quot;:0,&quot;color&quot;:&quot;black&quot;,&quot;id&quot;:&quot;zero&quot;,&quot;value&quot;:1},{&quot;size&quot;:1,&quot;pos&quot;:100,&quot;color&quot;:&quot;black&quot;,&quot;id&quot;:&quot;zero&quot;,&quot;value&quot;:1000}],&quot;genId&quot;:&quot;1339212400&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/playground','../javascripts/notebook/magic/customPlotlyChart'], \n      function(playground, _magiccustomPlotlyChart) {\n        // data ==> data-this (in observable.js's scopedEval) ==> this in JS => { dataId, dataInit, ... }\n        // this ==> scope (in observable.js's scopedEval) ==> this.parentElement ==> div.container below (toHtml)\n\n        playground.call(data,\n                        this\n                        ,\n                        {\n    \"f\": _magiccustomPlotlyChart,\n    \"o\": {\"js\":\"var layout = {title: 'Anomaly Board', showlegend: false, height: 800, width: 1000}; var dataSources={x: 'pos', y: 'value',text: 'id', marker: {size: 'size', color: 'color'}}; var dataOptions = {mode: 'markers'}; var extraOptions = {}\",\"headers\":[\"id\",\"size\",\"value\",\"pos\",\"color\"],\"height\":400}\n  }\n  \n                        \n                        \n                      );\n      }\n    );/*]]>*/</script>\n    <div>\n      <span class=\"chart-total-item-count\"><p data-bind=\"text: value\"><script data-this=\"{&quot;valueId&quot;:&quot;anon78109af5e26489181b36e08931c0b4a1&quot;,&quot;initialValue&quot;:&quot;2&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/\nreq(\n['observable', 'knockout'],\nfunction (O, ko) {\n  ko.applyBindings({\n      value: O.makeObservable(valueId, initialValue)\n    },\n    this\n  );\n});\n        /*]]>*/</script></p> entries total</span>\n      <span class=\"chart-sampling-warning\"><p data-bind=\"text: value\"><script data-this=\"{&quot;valueId&quot;:&quot;anond63040957715e7f067a21c2f745c73ba&quot;,&quot;initialValue&quot;:&quot;&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/\nreq(\n['observable', 'knockout'],\nfunction (O, ko) {\n  ko.applyBindings({\n      value: O.makeObservable(valueId, initialValue)\n    },\n    this\n  );\n});\n        /*]]>*/</script></p></span>\n      <div>\n      </div>\n    </div></div>"
      },
      "output_type" : "execute_result",
      "execution_count" : 12,
      "time" : "Took: 1.448s, at 2018-12-06 15:44"
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true,
      "id" : "0EC652F52A2746188A6D3938E431DC26"
    },
    "cell_type" : "code",
    "source" : [ "" ],
    "outputs" : [ ]
  } ],
  "nbformat" : 4
}