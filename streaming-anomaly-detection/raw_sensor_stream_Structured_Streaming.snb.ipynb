{
  "metadata" : {
    "id" : "7ac8f601-5e0c-424b-8f8a-5a21d76bc003",
    "name" : "raw_sensor_stream_Structured_Streaming",
    "user_save_timestamp" : "1970-01-01T01:00:00.000Z",
    "auto_save_timestamp" : "1970-01-01T01:00:00.000Z",
    "language_info" : {
      "name" : "scala",
      "file_extension" : "scala",
      "codemirror_mode" : "text/x-scala"
    },
    "trusted" : true,
    "sparkNotebook" : null,
    "customLocalRepo" : null,
    "customRepos" : null,
    "customDeps" : [ "org.apache.spark %% spark-sql-kafka-0-10 % 2.3.0" ],
    "customImports" : null,
    "customArgs" : null,
    "customSparkConf" : null,
    "customVars" : null
  },
  "cells" : [ {
    "metadata" : {
      "id" : "6E2995E02B244E978E1327B7A60484F0"
    },
    "cell_type" : "markdown",
    "source" : "# Processing Sensor Data from Kafka with Structured Streaming\n\nThe intention of this example is to explore how to consume and produce data with Structured Streaming API.\n\nUsing the data produced by the Akka ingestion microservice and produced to Kafka, we will: \n - use the Kafka `source` to consume events from the `sensor-raw` topic in Kafka\n - implement the application logic using the Dataset API\n - use the `memory` sink to visualize the data\n - use the `kafka` sink to publish our results to a different topic and make it available downstream.\n - have some fun!  "
  }, {
    "metadata" : {
      "id" : "CA367DA2510C4533840296E5D4704D43"
    },
    "cell_type" : "markdown",
    "source" : "##Common Definitions\nWe define a series of parameters of our current environment"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "3B783C2DA5A9409E85DF2CE7F061AECB"
    },
    "cell_type" : "code",
    "source" : [ "val sourceTopic = \"sensor-raw\"\n", "val targetTopic = \"sensor-processed\"\n", "val kafkaBootstrapServer = \"172.17.0.2:9092\" // local\n", "// val kafkaBootstrapServer = \"10.2.2.191:1025\" // fast-data-ec2" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "sourceTopic: String = sensor-raw\ntargetTopic: String = sensor-processed\nkafkaBootstrapServer: String = 172.17.0.2:9092\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 1,
      "time" : "Took: 0.904s, at 2018-12-05 22:12"
    } ]
  }, {
    "metadata" : {
      "id" : "B202F3190F3E457A85A995D2544AAA45"
    },
    "cell_type" : "markdown",
    "source" : "# PART I: Read and Visualize a Stream from Kafka"
  }, {
    "metadata" : {
      "id" : "B42E8EC94CAC48A093E2E1ED7CF84E3F"
    },
    "cell_type" : "markdown",
    "source" : "## Read a stream from Kafka\nWe use the kafka source to subscribe to the `sourceTopic` that contains the raw sensor data.\nThis results in a streaming dataframe that we use to operate on the underlying data"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "3225F1A3939642B087F1BE6A37EB9D03"
    },
    "cell_type" : "code",
    "source" : [ "val rawData = sparkSession.readStream\n", "      .format(\"kafka\")\n", "      .option(\"kafka.bootstrap.servers\", kafkaBootstrapServer)\n", "      .option(\"subscribe\", sourceTopic)\n", "      .option(\"startingOffsets\", \"latest\")\n", "      .load()" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "rawData: org.apache.spark.sql.DataFrame = [key: binary, value: binary ... 5 more fields]\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 1,
      "time" : "Took: 1.673s, at 2018-12-05 22:13"
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "497CEEFAB7DF40F884CC7A8139C3DA5F"
    },
    "cell_type" : "code",
    "source" : [ "rawData.isStreaming" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "res3: Boolean = true\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : "true"
      },
      "output_type" : "execute_result",
      "execution_count" : 2,
      "time" : "Took: 0.992s, at 2018-12-05 22:13"
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "A74BF086DCC240168F21E57797088678"
    },
    "cell_type" : "code",
    "source" : [ "rawData.printSchema()" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "root\n |-- key: binary (nullable = true)\n |-- value: binary (nullable = true)\n |-- topic: string (nullable = true)\n |-- partition: integer (nullable = true)\n |-- offset: long (nullable = true)\n |-- timestamp: timestamp (nullable = true)\n |-- timestampType: integer (nullable = true)\n\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 3,
      "time" : "Took: 0.862s, at 2018-12-05 22:13"
    } ]
  }, {
    "metadata" : {
      "id" : "F2782E9257024A819A1ADAAC2EFB1238"
    },
    "cell_type" : "markdown",
    "source" : "## Extract the payload from the `value` field\n\n- The data in Kafka is contained in the `value` field of the message envelop. \n- To parse that payload, we need to know the schema of the data in the stream.\n- We use a `case class` to define that schema. \n\n_Tip: This method is more convenient than using the sql schema definition directly._"
  }, {
    "metadata" : {
      "id" : "8E4FC094403D49B78D312AFCB3BFDF57"
    },
    "cell_type" : "markdown",
    "source" : "### Declare the Schema"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "A39D7FB1A9AC496F8DFC7502EB0A4C29"
    },
    "cell_type" : "code",
    "source" : [ "case class SensorData(id: String, ts: Long, value: Double)" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "defined class SensorData\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 1,
      "time" : "Took: 0.601s, at 2018-12-05 22:23"
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "presentation" : {
        "tabs_state" : "{\n  \"tab_id\": \"#tab2093373533-0\"\n}",
        "pivot_chart_state" : "{\n  \"hiddenAttributes\": [],\n  \"menuLimit\": 200,\n  \"cols\": [],\n  \"rows\": [],\n  \"vals\": [],\n  \"exclusions\": {},\n  \"inclusions\": {},\n  \"unusedAttrsVertical\": 85,\n  \"autoSortUnusedAttrs\": false,\n  \"inclusionsInfo\": {},\n  \"aggregatorName\": \"Count\",\n  \"rendererName\": \"Table\"\n}"
      },
      "id" : "89E72AB850BC4AE7812D0236B3F51CED"
    },
    "cell_type" : "code",
    "source" : [ "import org.apache.spark.sql.Encoders\n", "val schema = Encoders.product[SensorData].schema" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "import org.apache.spark.sql.Encoders\nschema: org.apache.spark.sql.types.StructType = StructType(StructField(id,StringType,true), StructField(ts,LongType,false), StructField(value,DoubleType,false))\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 2,
      "time" : "Took: 1.383s, at 2018-12-05 22:23"
    } ]
  }, {
    "metadata" : {
      "id" : "1DB49CA4BD7E4BA19AFBECF7D195CF27"
    },
    "cell_type" : "markdown",
    "source" : "### Parse the Data\nTo transform the data in the payload, we need to:\n- convert that binary value field to string\n- use the `json` support in Spark to transform our incoming data into a structured streaming `Dataset`\n- select the fields from the record to facilitate further processing\n"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "6E729EE3495E4AA88FC9E347BDEE3210"
    },
    "cell_type" : "code",
    "source" : [ "val rawValues = rawData.selectExpr(\"CAST(value AS STRING)\").as[String]\n", "val jsonValues = rawValues.select(from_json($\"value\", schema) as \"record\")\n", "val sensorData = jsonValues.select(\"record.*\").as[SensorData]" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "rawValues: org.apache.spark.sql.Dataset[String] = [value: string]\njsonValues: org.apache.spark.sql.DataFrame = [record: struct<id: string, ts: bigint ... 1 more field>]\nsensorData: org.apache.spark.sql.Dataset[SensorData] = [id: string, ts: bigint ... 1 more field]\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 1,
      "time" : "Took: 1.025s, at 2018-12-05 22:27"
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "F69903037F07494EA9A42815B386C0A4"
    },
    "cell_type" : "code",
    "source" : [ "sensorData.printSchema()" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "root\n |-- id: string (nullable = true)\n |-- ts: long (nullable = true)\n |-- value: double (nullable = true)\n\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 2,
      "time" : "Took: 0.692s, at 2018-12-05 22:27"
    } ]
  }, {
    "metadata" : {
      "id" : "E579B7773A82414885636B662D189409"
    },
    "cell_type" : "markdown",
    "source" : "## Visualize the Stream\nTo view the streaming data, we will use the `memory` sink and query the resulting table to get samples of the data."
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "0A62B3731D884D1185F153937359EB80"
    },
    "cell_type" : "code",
    "source" : [ "val visualizationQuery = sensorData.writeStream\n", "  .queryName(\"visualization\")    // this query name will be the SQL table name\n", "  .outputMode(\"append\")\n", "  .format(\"memory\")\n", "  .start()" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "visualizationQuery: org.apache.spark.sql.streaming.StreamingQuery = org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@4f153d5a\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 3,
      "time" : "Took: 1.056s, at 2018-12-05 22:28"
    } ]
  }, {
    "metadata" : {
      "id" : "2E96BBE34C994DEA8CD5200022660825"
    },
    "cell_type" : "markdown",
    "source" : "## Explore the Data\nThe `memory` sink creates an in-memory SQL table (like a `tempTable`) that we can query using Spark SQL\nThe result of the query is a static `Dataframe` that contains a snapshot of the data."
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "3A8498745D0E4A86BFB12ED10544529E"
    },
    "cell_type" : "code",
    "source" : [ "val sampleDataset = sparkSession.sql(\"select * from visualization\")\n" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "sampleDataset: org.apache.spark.sql.DataFrame = [id: string, ts: bigint ... 1 more field]\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 5,
      "time" : "Took: 0.752s, at 2018-12-05 22:29"
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "761D964930424D448539675AE8C0E631"
    },
    "cell_type" : "code",
    "source" : [ "sampleDataset" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "res19: org.apache.spark.sql.DataFrame = [id: string, ts: bigint ... 1 more field]\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : "<div class=\"df-canvas\">\n      <script data-this=\"{&quot;dataId&quot;:&quot;anon7c67741f0c097466b348894fbbb2ab02&quot;,&quot;partitionIndexId&quot;:&quot;anond28989dcec51f3c49a185554cbd70370&quot;,&quot;numPartitions&quot;:2808,&quot;dfSchema&quot;:{&quot;type&quot;:&quot;struct&quot;,&quot;fields&quot;:[{&quot;name&quot;:&quot;id&quot;,&quot;type&quot;:&quot;string&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;ts&quot;,&quot;type&quot;:&quot;long&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;value&quot;,&quot;type&quot;:&quot;double&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}}]}}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/dataframe','../javascripts/notebook/consoleDir'], \n      function(dataframe, extension) {\n        dataframe.call(data, this, extension);\n      }\n    );/*]]>*/</script>\n      <link rel=\"stylesheet\" href=\"/assets/stylesheets/ipython/css/dataframe.css\" type=\"text/css\"/>\n    </div>"
      },
      "output_type" : "execute_result",
      "execution_count" : 7,
      "time" : "Took: 1.333s, at 2018-12-05 23:02"
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "A7BE1142BA7F478DBD40DD167000E930"
    },
    "cell_type" : "code",
    "source" : [ "sampleDataset.count" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "res21: Long = 70394\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : "70394"
      },
      "output_type" : "execute_result",
      "execution_count" : 8,
      "time" : "Took: 2.193s, at 2018-12-05 23:02"
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "6746B72D7F5D40EEA68EBBA2911BEF37"
    },
    "cell_type" : "code",
    "source" : [ "sampleDataset.count" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "res29: Long = 118065\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : "118065"
      },
      "output_type" : "execute_result",
      "execution_count" : 14,
      "time" : "Took: 1.306s, at 2018-12-05 23:25"
    } ]
  }, {
    "metadata" : {
      "id" : "0693F6BC6F6E422281CFDB057D95F707"
    },
    "cell_type" : "markdown",
    "source" : "## Visualize the Data\nWe make a custom live update by querying the stream every so often for the latest updates"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "6D330DDECB47432C8B2C534C9E9291FF"
    },
    "cell_type" : "code",
    "source" : [ "val dummy = Seq((System.currentTimeMillis, 0.1), (System.currentTimeMillis, 0.1))\n", "\n", "val chart = CustomPlotlyChart(dummy,\n", "                  layout=\"{title: 'sensor data sample', xaxis: {title: 'time(seconds)'}, yaxis: {title: 'value'}}\",\n", "                  dataOptions=\"\"\"{type: 'line'}\"\"\",\n", "                  dataSources=\"{x: '_1', y: '_2' }\")" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "dummy: Seq[(Long, Double)] = List((1544049205981,0.1), (1544049205981,0.1))\nchart: notebook.front.widgets.charts.CustomPlotlyChart[Seq[(Long, Double)]] = <CustomPlotlyChart widget>\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 26,
      "time" : "Took: 0.715s, at 2018-12-05 23:33"
    } ]
  }, {
    "metadata" : {
      "id" : "C96D62E1D7754A2F8C9CCCB23C2D4E29"
    },
    "cell_type" : "markdown",
    "source" : "### Some Thread Magic ahead: Async update of our visualization\nWe will use a plain old Thread to run a recurrent query on our in-memory table and update the chart accordingly.\n"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "D496C339A4F24B9F8038D2DA970220E5"
    },
    "cell_type" : "code",
    "source" : [ "@volatile var running = true" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "running: Boolean = true\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 29,
      "time" : "Took: 0.562s, at 2018-12-05 23:34"
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "645C005ED2D843EF81E0A96329F9C7D4"
    },
    "cell_type" : "code",
    "source" : [ "import scala.concurrent.duration._\n", "import scala.annotation.tailrec\n", "\n", "val updater = new Thread() {\n", "  @tailrec\n", "  def visualize(): Unit = {\n", "    val lastMinute = System.currentTimeMillis - 1.minute.toMillis\n", "    val data = sampleDataset.where($\"ts\" > lastMinute and $\"id\" === \"office\").as[SensorData]\n", "                            .map{case SensorData(id, ts, value) => (ts/1000%3600, value)}.collect\n", "    if (data.size > 0 )chart.applyOn(data)\n", "    if (running) {\n", "      Thread.sleep(1.second.toMillis)\n", "      visualize()\n", "    } else ()\n", "  } \n", "  \n", "  override def run() {\n", "    visualize()\n", "  }\n", "}.start()\n" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "import scala.concurrent.duration._\nimport scala.annotation.tailrec\nupdater: Unit = ()\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 30,
      "time" : "Took: 0.798s, at 2018-12-05 23:34"
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "FDF98A5CE00E4CAD89A9BEA802A0C16F"
    },
    "cell_type" : "code",
    "source" : [ "chart" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "res47: notebook.front.widgets.charts.CustomPlotlyChart[Seq[(Long, Double)]] = <CustomPlotlyChart widget>\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : "<div>\n      <script data-this=\"{&quot;dataId&quot;:&quot;anon0c2e92dd32797930007374592e91a264&quot;,&quot;dataInit&quot;:[{&quot;_1&quot;:1544049205981,&quot;_2&quot;:0.1},{&quot;_1&quot;:1544049205981,&quot;_2&quot;:0.1}],&quot;genId&quot;:&quot;1007013445&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/playground','../javascripts/notebook/magic/customPlotlyChart'], \n      function(playground, _magiccustomPlotlyChart) {\n        // data ==> data-this (in observable.js's scopedEval) ==> this in JS => { dataId, dataInit, ... }\n        // this ==> scope (in observable.js's scopedEval) ==> this.parentElement ==> div.container below (toHtml)\n\n        playground.call(data,\n                        this\n                        ,\n                        {\n    \"f\": _magiccustomPlotlyChart,\n    \"o\": {\"js\":\"var layout = {title: 'sensor data sample', xaxis: {title: 'time(seconds)'}, yaxis: {title: 'value'}}; var dataSources={x: '_1', y: '_2' }; var dataOptions = {type: 'line'}; var extraOptions = {}\",\"headers\":[\"_1\",\"_2\"],\"height\":400}\n  }\n  \n                        \n                        \n                      );\n      }\n    );/*]]>*/</script>\n    <div>\n      <span class=\"chart-total-item-count\"><p data-bind=\"text: value\"><script data-this=\"{&quot;valueId&quot;:&quot;anonf48252a9fd30e17653d8ad0a7e8ceefc&quot;,&quot;initialValue&quot;:&quot;2&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/\nreq(\n['observable', 'knockout'],\nfunction (O, ko) {\n  ko.applyBindings({\n      value: O.makeObservable(valueId, initialValue)\n    },\n    this\n  );\n});\n        /*]]>*/</script></p> entries total</span>\n      <span class=\"chart-sampling-warning\"><p data-bind=\"text: value\"><script data-this=\"{&quot;valueId&quot;:&quot;anond88eacfde81da3b5b66892679655da11&quot;,&quot;initialValue&quot;:&quot;&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/\nreq(\n['observable', 'knockout'],\nfunction (O, ko) {\n  ko.applyBindings({\n      value: O.makeObservable(valueId, initialValue)\n    },\n    this\n  );\n});\n        /*]]>*/</script></p></span>\n      <div>\n      </div>\n    </div></div>"
      },
      "output_type" : "execute_result",
      "execution_count" : 27,
      "time" : "Took: 0.783s, at 2018-12-05 23:33"
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "5F80EB02EB934828854A917DBF7D0DE1"
    },
    "cell_type" : "code",
    "source" : [ "visualizationQuery.stop()\n" ],
    "outputs" : [ {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 31,
      "time" : "Took: 0.887s, at 2018-12-05 23:35"
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "AA02762A61C0493FBBFB00CD9E682B5A"
    },
    "cell_type" : "code",
    "source" : [ "running = false" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "running: Boolean = false\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 32,
      "time" : "Took: 0.473s, at 2018-12-05 23:35"
    } ]
  }, {
    "metadata" : {
      "id" : "C117BCB1949C412B9B143C8E120C7C14"
    },
    "cell_type" : "markdown",
    "source" : "# PART II: Improve Data Quality"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "A8292D947D7E4A889B416F5C2BB158C7"
    },
    "cell_type" : "markdown",
    "source" : "## Reduce noise with a moving average, using sliding windows\n"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "BD00015ED0564F9B9F405737792E7743"
    },
    "cell_type" : "code",
    "source" : [ "import org.apache.spark.sql.types._" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "import org.apache.spark.sql.types._\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 14,
      "time" : "Took: 0.762s, at 2018-12-05 16:26"
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "BBDA2F693B6247DD8849298DA0BC769B"
    },
    "cell_type" : "code",
    "source" : [ "val toSeconds = udf((ts:Long) => ts/1000)\n", "val sensorMovingAverage = sensorData.withColumn(\"timestamp\", toSeconds($\"ts\").cast(TimestampType))\n", "                                          .withWatermark(\"timestamp\", \"30 seconds\")\n", "                                          .groupBy($\"id\", window($\"timestamp\", \"30 seconds\", \"10 seconds\"))\n", "                                          .agg(avg($\"temp\"))" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "toSeconds: org.apache.spark.sql.expressions.UserDefinedFunction = UserDefinedFunction(<function1>,LongType,Some(List(LongType)))\nsensorMovingAverage: org.apache.spark.sql.DataFrame = [id: string, window: struct<start: timestamp, end: timestamp> ... 1 more field]\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 15,
      "time" : "Took: 1.057s, at 2018-12-05 16:26"
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "9BF82601363C40579E8DBC9AF9AC2F89"
    },
    "cell_type" : "code",
    "source" : [ "sensorMovingAverage.printSchema" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "root\n |-- id: string (nullable = true)\n |-- window: struct (nullable = true)\n |    |-- start: timestamp (nullable = true)\n |    |-- end: timestamp (nullable = true)\n |-- avg(temp): double (nullable = true)\n\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 16,
      "time" : "Took: 0.836s, at 2018-12-05 16:26"
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "414735A902F34CDE84D1C3642D512973"
    },
    "cell_type" : "code",
    "source" : [ "val windowedSensorQuery = sensorMovingAverage.writeStream\n", "  .queryName(\"movingAverage\")    // this query name will be the table name\n", "  .outputMode(\"append\")  \n", "  .format(\"memory\")\n", "  .start()" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "windowedSensorQuery: org.apache.spark.sql.streaming.StreamingQuery = org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@34822989\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 17,
      "time" : "Took: 0.791s, at 2018-12-05 16:27"
    } ]
  }, {
    "metadata" : {
      "id" : "DF8FC71EEC3142C6852A411BF1C54DBC"
    },
    "cell_type" : "markdown",
    "source" : "### Get the data from the in-memory table"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "89EE4EF3EFA845D987484FE216C865A3"
    },
    "cell_type" : "code",
    "source" : [ "val movingAvgDF = sparkSession.sql(\"select * from movingAverage\")" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "movingAvgDF: org.apache.spark.sql.DataFrame = [id: string, window: struct<start: timestamp, end: timestamp> ... 1 more field]\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 18,
      "time" : "Took: 0.759s, at 2018-12-05 16:27"
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "2E71B78A71D543358203125FE62FE6F5"
    },
    "cell_type" : "code",
    "source" : [ "movingAvgDF" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "res39: org.apache.spark.sql.DataFrame = [id: string, window: struct<start: timestamp, end: timestamp> ... 1 more field]\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : "<div class=\"df-canvas\">\n      <script data-this=\"{&quot;dataId&quot;:&quot;anon48c88d801ecc5c0cd1778ef31e1e46cf&quot;,&quot;partitionIndexId&quot;:&quot;anon2b3f89c6547d873a2eb366ca2ff36574&quot;,&quot;numPartitions&quot;:88,&quot;dfSchema&quot;:{&quot;type&quot;:&quot;struct&quot;,&quot;fields&quot;:[{&quot;name&quot;:&quot;id&quot;,&quot;type&quot;:&quot;string&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;window&quot;,&quot;type&quot;:{&quot;type&quot;:&quot;struct&quot;,&quot;fields&quot;:[{&quot;name&quot;:&quot;start&quot;,&quot;type&quot;:&quot;timestamp&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;end&quot;,&quot;type&quot;:&quot;timestamp&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}}]},&quot;nullable&quot;:true,&quot;metadata&quot;:{&quot;spark.watermarkDelayMs&quot;:30000}},{&quot;name&quot;:&quot;avg(temp)&quot;,&quot;type&quot;:&quot;double&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}}]}}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/dataframe','../javascripts/notebook/consoleDir'], \n      function(dataframe, extension) {\n        dataframe.call(data, this, extension);\n      }\n    );/*]]>*/</script>\n      <link rel=\"stylesheet\" href=\"/assets/stylesheets/ipython/css/dataframe.css\" type=\"text/css\"/>\n    </div>"
      },
      "output_type" : "execute_result",
      "execution_count" : 21,
      "time" : "Took: 1.606s, at 2018-12-05 16:28"
    } ]
  }, {
    "metadata" : {
      "id" : "32708913EB914EAB8268E52A0F69296F"
    },
    "cell_type" : "markdown",
    "source" : "### Chart the Moving Average Data"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "AA5DF0B0AD6D4EF093A9879DB10A106E"
    },
    "cell_type" : "code",
    "source" : [ "import org.apache.spark.sql.functions._\n", "val lastMinute: Long = System.currentTimeMillis/1000 - 5.minute.toSeconds\n", "val mAvgSample = movingAvgDF.select($\"window.start\".cast(LongType) as \"timestamp\", $\"avg(temp)\" as \"temp\")\n", "                   .where($\"timestamp\" > lastMinute and $\"id\" === \"office\")\n", "                   .orderBy($\"timestamp\")\n", "                   .as[(Long, Double)]\n", "                   .collect().map{case (ts, v) => (ts  % 3600,v)}\n", "\n", "\n", "CustomPlotlyChart(mAvgSample,\n", "                  layout=s\"{title: 'moving average sensor data'}\",\n", "                  dataOptions=\"\"\"{type: 'line'}\"\"\",\n", "                  dataSources=\"{x: '_1', y: '_2'}\")" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "import org.apache.spark.sql.functions._\nlastMinute: Long = 1544023424\nmAvgSample: Array[(Long, Double)] = Array((1600,34.5), (1610,33.833333333333336), (1620,32.80952380952381), (1630,32.793103448275865), (1640,32.55172413793103), (1650,37.7), (1660,39.41379310344828))\nres41: notebook.front.widgets.charts.CustomPlotlyChart[Array[(Long, Double)]] = <CustomPlotlyChart widget>\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : "<div>\n      <script data-this=\"{&quot;dataId&quot;:&quot;anon49a949432563e924e8f6a21c13951cdb&quot;,&quot;dataInit&quot;:[{&quot;_1&quot;:1600,&quot;_2&quot;:34.5},{&quot;_1&quot;:1610,&quot;_2&quot;:33.833333333333336},{&quot;_1&quot;:1620,&quot;_2&quot;:32.80952380952381},{&quot;_1&quot;:1630,&quot;_2&quot;:32.793103448275865},{&quot;_1&quot;:1640,&quot;_2&quot;:32.55172413793103},{&quot;_1&quot;:1650,&quot;_2&quot;:37.7},{&quot;_1&quot;:1660,&quot;_2&quot;:39.41379310344828}],&quot;genId&quot;:&quot;631467&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/playground','../javascripts/notebook/magic/customPlotlyChart'], \n      function(playground, _magiccustomPlotlyChart) {\n        // data ==> data-this (in observable.js's scopedEval) ==> this in JS => { dataId, dataInit, ... }\n        // this ==> scope (in observable.js's scopedEval) ==> this.parentElement ==> div.container below (toHtml)\n\n        playground.call(data,\n                        this\n                        ,\n                        {\n    \"f\": _magiccustomPlotlyChart,\n    \"o\": {\"js\":\"var layout = {title: 'moving average sensor data'}; var dataSources={x: '_1', y: '_2'}; var dataOptions = {type: 'line'}; var extraOptions = {}\",\"headers\":[\"_1\",\"_2\"],\"height\":400}\n  }\n  \n                        \n                        \n                      );\n      }\n    );/*]]>*/</script>\n    <div>\n      <span class=\"chart-total-item-count\"><p data-bind=\"text: value\"><script data-this=\"{&quot;valueId&quot;:&quot;anon0ef478eeb4791c2b841d6440c8ad0d10&quot;,&quot;initialValue&quot;:&quot;7&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/\nreq(\n['observable', 'knockout'],\nfunction (O, ko) {\n  ko.applyBindings({\n      value: O.makeObservable(valueId, initialValue)\n    },\n    this\n  );\n});\n        /*]]>*/</script></p> entries total</span>\n      <span class=\"chart-sampling-warning\"><p data-bind=\"text: value\"><script data-this=\"{&quot;valueId&quot;:&quot;anonbb014838ab99a514214fb3373b648da8&quot;,&quot;initialValue&quot;:&quot;&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/\nreq(\n['observable', 'knockout'],\nfunction (O, ko) {\n  ko.applyBindings({\n      value: O.makeObservable(valueId, initialValue)\n    },\n    this\n  );\n});\n        /*]]>*/</script></p></span>\n      <div>\n      </div>\n    </div></div>"
      },
      "output_type" : "execute_result",
      "execution_count" : 22,
      "time" : "Took: 4.062s, at 2018-12-05 16:28"
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false,
      "id" : "B39288CF67F04535870AE968E0700074"
    },
    "cell_type" : "code",
    "source" : [ "// stop the ancilliary visualization queries\n", "windowedSensorQuery.stop()\n", "visualizationQuery.stop()\n", "running = false" ],
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "running: Boolean = false\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 23,
      "time" : "Took: 5.086s, at 2018-12-05 16:29"
    } ]
  }, {
    "metadata" : {
      "id" : "495EC81428014BC4AE7CD9DE863EFB06"
    },
    "cell_type" : "markdown",
    "source" : "## Write our moving average data to our `sensor-clean` topic"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true,
      "id" : "707C86245D9542F384FFC006900AA88D"
    },
    "cell_type" : "code",
    "source" : [ "// First we prepare the schema to comply with the (key, value) model of Kafka\n", "val kafkaFormat = sensorMovingAverage\n", ".select($\"id\", $\"window.start\".cast(LongType) as \"timestamp\", $\"avg(temp)\" as \"temp\")\n", ".select($\"id\" as \"key\", to_json(struct($\"id\", $\"timestamp\", $\"temp\")) as \"value\")" ],
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true,
      "id" : "AF7660F21370444A89C197C94930052E"
    },
    "cell_type" : "code",
    "source" : [ "val kafkaWriterQuery = kafkaFormat.writeStream\n", "  .queryName(\"kafkaWriter\") \n", "  .outputMode(\"append\") \n", "  .format(\"kafka\")\n", "  .option(\"kafka.bootstrap.servers\", kafkaBootstrapServer)\n", "  .option(\"topic\", targetTopic)\n", "  .option(\"checkpointLocation\", \"/tmp/spark/checkpoint6\")\n", "  .option(\"failOnDataLoss\", \"false\")\n", "  .start()" ],
    "outputs" : [ ]
  }, {
    "metadata" : {
      "id" : "C1A1F325212A4601910959A098B6E22A"
    },
    "cell_type" : "markdown",
    "source" : "## View Progress"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true,
      "presentation" : {
        "tabs_state" : "{\n  \"tab_id\": \"#tab1300593006-0\"\n}",
        "pivot_chart_state" : "{\n  \"hiddenAttributes\": [],\n  \"menuLimit\": 200,\n  \"cols\": [],\n  \"rows\": [],\n  \"vals\": [],\n  \"exclusions\": {},\n  \"inclusions\": {},\n  \"unusedAttrsVertical\": 85,\n  \"autoSortUnusedAttrs\": false,\n  \"inclusionsInfo\": {},\n  \"aggregatorName\": \"Count\",\n  \"rendererName\": \"Table\"\n}"
      },
      "id" : "F359A73CFAF04B978876322746ECF620"
    },
    "cell_type" : "code",
    "source" : [ "val progress = kafkaWriterQuery.recentProgress" ],
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true,
      "presentation" : {
        "tabs_state" : "{\n  \"tab_id\": \"#tab1337165318-1\"\n}",
        "pivot_chart_state" : "{\n  \"hiddenAttributes\": [],\n  \"menuLimit\": 200,\n  \"cols\": [],\n  \"rows\": [],\n  \"vals\": [],\n  \"exclusions\": {},\n  \"inclusions\": {},\n  \"unusedAttrsVertical\": 85,\n  \"autoSortUnusedAttrs\": false,\n  \"inclusionsInfo\": {},\n  \"aggregatorName\": \"Count\",\n  \"rendererName\": \"Table\"\n}"
      },
      "id" : "06AFEE5AE0764ECCB6F01239CF4267B9"
    },
    "cell_type" : "code",
    "source" : [ "progress.map(entry  => (entry.inputRowsPerSecond, entry.processedRowsPerSecond))" ],
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true,
      "id" : "1EBD79F917FA447F80703F4717B1FC83"
    },
    "cell_type" : "code",
    "source" : [ "" ],
    "outputs" : [ ]
  } ],
  "nbformat" : 4
}