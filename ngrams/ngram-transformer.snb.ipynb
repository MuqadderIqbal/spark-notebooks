{
  "metadata" : {
    "id" : "95db5a33-2c18-45f0-80ee-057ba1ea1db6",
    "name" : "ngram-transformer",
    "user_save_timestamp" : "1970-01-01T01:00:00.000Z",
    "auto_save_timestamp" : "1970-01-01T01:00:00.000Z",
    "language_info" : {
      "name" : "scala",
      "file_extension" : "scala",
      "codemirror_mode" : "text/x-scala"
    },
    "trusted" : true,
    "sparkNotebook" : null,
    "customLocalRepo" : null,
    "customRepos" : null,
    "customDeps" : null,
    "customImports" : null,
    "customArgs" : null,
    "customSparkConf" : null,
    "customVars" : null
  },
  "cells" : [
    {
      "metadata" : {
        "id" : "9F0F316DF69C4F378FD88FAAFD718053"
      },
      "cell_type" : "markdown",
      "source" : "#n-gram based language ML Classifier\n###This notebook implements the method described by  Cavnar and Trenkle in the paper [N-Gram-Based Text Categorization](http://odur.let.rug.nl/~vannoord/TextCat/textcat.pdf)\nn-grams are continuos segments of size 'n' taken from a given string. Given the sentence _\"cavnar and trenkle\"_, \n- bi-grams: `ca,av,vn,na,ar,r_,_a,an,nd,d_,_t,tr,re,en,nk,kl,le,e_`\n- tri-grams: `cav,avn,vna,nar,ar_,r_a,_an,and,nd_,d_t,_tr,tre,ren,enk,nkl,kle,le_`\n- quad-grams: `cavn,...`\n\nNext to the frequency of letter (one-gram) that we explored in [A naive approach to language classification](/notebooks/languageclassification/language-detection-letter-freq.snb) they also capture common letter combinations that are typical in a language. n-grams where n>1 also provide record of start and end of words, further adding features to the language classification model that we can create with it."
    },
    {
      "metadata" : {
        "id" : "2D7D377CAB9241C5B114A4BF3C95EC70"
      },
      "cell_type" : "markdown",
      "source" : "## Define data location"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "5AEA5BEEBE1C40E092C3E5047A2B40B7"
      },
      "cell_type" : "code",
      "source" : [
        "val notebooksFolder = sys.env(\"NOTEBOOKS_DIR\")\n",
        "val baseFolder = s\"$notebooksFolder/languageclassification/data\""
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "notebooksFolder: String = /home/maasg/playground/sparkfun/spark-notebooks\nbaseFolder: String = /home/maasg/playground/sparkfun/spark-notebooks/languageclassification/data\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 1,
          "time" : "Took: 1.327s, at 2017-09-26 13:46"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "AD6F13F5AD2745D58F5E6F2C44B40C36"
      },
      "cell_type" : "markdown",
      "source" : "### `NgramLanguageClassifier` becomes a `Model[NgramLanguageClassifier]` to use with an `Estimator`"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "CF83DFCB586F4E008AF260C4D5B08C01"
      },
      "cell_type" : "code",
      "source" : [
        "import org.apache.spark.ml.Model\n",
        "import org.apache.spark.sql._\n",
        "import org.apache.spark.ml.param._\n",
        "import org.apache.spark.sql.types._\n",
        "import org.apache.spark.ml.util.Identifiable\n",
        "import org.apache.spark.sql.types.{DataType, DataTypes}\n",
        "import org.apache.spark.sql.functions.udf\n",
        "\n",
        "class NgramLanguageClassifier(override val uid: String, model: Seq[(String, Map[String,Int])]) extends \n",
        "Model[NgramLanguageClassifier] with Serializable {\n",
        "  \n",
        "  val ProfileCutPoint = 300\n",
        "\n",
        "  val ngrams: String => Seq[String] = str => {\n",
        "    val cleaned = str.toLowerCase.replaceAll(\"[^A-zÀ-ÿ'’]+\", \"_\").reverse.dropWhile(_ == '_').reverse\n",
        "\n",
        "    def _ngram(n:Int) : Seq[String] = {\n",
        "      if (n == 1) {\n",
        "        cleaned.collect{case c if c != '_' => c.toString}\n",
        "      } else {\n",
        "        val padding = Seq.fill(n - 1)(\"_\").mkString(\"\")\n",
        "        val padded = \"_\" + cleaned + padding\n",
        "        padded.sliding(n,1).toSeq\n",
        "      }\n",
        "    }\n",
        "    (1 to Math.min(cleaned.size, 5)).flatMap(i => _ngram(i))\n",
        "  }\n",
        "  \n",
        "  val ngramProfile: Seq[String] => Seq[(Int, String)] = ngrams => {\n",
        "     ngrams\n",
        "    .groupBy(identity)\n",
        "    .map{case (k, col) => k -> col.size } // do not use mapValues -> evil\n",
        "    .toSeq\n",
        "    .sortBy(- _._2)\n",
        "    .take(ProfileCutPoint)\n",
        "    .zipWithIndex\n",
        "    .map{case ((k,_),idx) => (idx,k)}\n",
        "  }\n",
        "  \n",
        "  val classifier: String => String = txt => {\n",
        "    val profile = (ngrams andThen ngramProfile)(txt)\n",
        "    val scores = model.map{case (lang, ngramMap) => \n",
        "                                  lang -> profile.map{case (idx, ngram) => \n",
        "                                                      ngramMap.get(ngram)\n",
        "                                                              .map(refIdx => Math.abs(refIdx - idx))\n",
        "                                                              .getOrElse(ProfileCutPoint)\n",
        "                                                     }.sum\n",
        "                                 }\n",
        "    scores.minBy(_._2)._1  \n",
        "  }\n",
        "\n",
        "  def createTransformFunc: String => String = classifier\n",
        "    \n",
        "  def outputDataType: DataType = DataTypes.StringType\n",
        "  \n",
        "  override def copy(extra: org.apache.spark.ml.param.ParamMap): NgramLanguageClassifier = defaultCopy(extra)\n",
        "  \n",
        "  override def transformSchema(schema: StructType): StructType = {\n",
        "    val inputType = schema($(inputCol)).dataType\n",
        "    validateInputType(inputType)\n",
        "    if (schema.fieldNames.contains($(outputCol))) {\n",
        "      throw new IllegalArgumentException(s\"Output column ${$(outputCol)} already exists.\")\n",
        "    }\n",
        "    val outputFields = schema.fields :+\n",
        "      StructField($(outputCol), outputDataType, nullable = false)\n",
        "    StructType(outputFields)\n",
        "  }\n",
        "\n",
        "  override def transform(dataset: Dataset[_]): DataFrame = {\n",
        "    transformSchema(dataset.schema, logging = true)\n",
        "    val transformUDF = udf(this.createTransformFunc, outputDataType)\n",
        "    dataset.withColumn($(outputCol), transformUDF(dataset($(inputCol))))\n",
        "  }\n",
        "  \n",
        "  def validateInputType(inputType: DataType): Unit = {\n",
        "    require(inputType == DataTypes.StringType, s\"Bad input type: $inputType. Requires String.\")\n",
        "  }\n",
        "  \n",
        "  final val inputCol: Param[String] = new Param[String](this, \"inputCol\", \"input column name\")\n",
        "\n",
        "  /** @group getParam */\n",
        "  final def getInputCol: String = $(inputCol)\n",
        "  \n",
        "  final val inputCols: StringArrayParam = new StringArrayParam(this, \"inputCols\", \"input column names\")\n",
        "\n",
        "  /** @group getParam */\n",
        "  final def getInputCols: Array[String] = $(inputCols)\n",
        "  \n",
        "  /**\n",
        "   * Param for output column name.\n",
        "   * @group param\n",
        "   */\n",
        "  final val outputCol: Param[String] = new Param[String](this, \"outputCol\", \"output column name\")\n",
        "\n",
        "  setDefault(outputCol, uid + \"__output\")\n",
        "\n",
        "  /** @group getParam */\n",
        "  final def getOutputCol: String = $(outputCol)\n",
        "  \n",
        "}"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "import org.apache.spark.ml.Model\nimport org.apache.spark.sql._\nimport org.apache.spark.ml.param._\nimport org.apache.spark.sql.types._\nimport org.apache.spark.ml.util.Identifiable\nimport org.apache.spark.sql.types.{DataType, DataTypes}\nimport org.apache.spark.sql.functions.udf\ndefined class NgramLanguageClassifier\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 17,
          "time" : "Took: 1.200s, at 2017-09-26 16:04"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "3B26D4A73F7744C48A0E3D5B67E089F6"
      },
      "cell_type" : "code",
      "source" : [
        "import org.apache.spark.ml.Estimator\n",
        "import org.apache.spark.sql._\n",
        "class NgramEstimator extends Estimator[NgramLanguageClassifier] {\n",
        "  override def fit(ds:Dataset[_]):NgramLanguageClassifier = ???\n",
        "  override def copy(extra: org.apache.spark.ml.param.ParamMap): org.apache.spark.ml.Estimator[NgramLanguageClassifier] = ???\n",
        "  val uid: String = ???\n",
        "  def transformSchema(schema: org.apache.spark.sql.types.StructType): org.apache.spark.sql.types.StructType = ???\n",
        "}"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "import org.apache.spark.ml.Estimator\nimport org.apache.spark.sql._\ndefined class NgramEstimator\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 25,
          "time" : "Took: 0.589s, at 2017-09-26 16:14"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "ED9663867C42485F865F4612E8B12782"
      },
      "cell_type" : "code",
      "source" : [
        ""
      ],
      "outputs" : [ ]
    }
  ],
  "nbformat" : 4
}