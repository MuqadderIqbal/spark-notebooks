{
  "metadata" : {
    "id" : "0da40699-353a-45b3-b9a7-41e64b455005",
    "name" : "raw_sensor_stream_Structured_Streaming",
    "user_save_timestamp" : "1970-01-01T01:00:00.000Z",
    "auto_save_timestamp" : "1970-01-01T01:00:00.000Z",
    "language_info" : {
      "name" : "scala",
      "file_extension" : "scala",
      "codemirror_mode" : "text/x-scala"
    },
    "trusted" : true,
    "sparkNotebook" : null,
    "customLocalRepo" : null,
    "customRepos" : null,
    "customDeps" : [
      "org.apache.spark %% spark-sql-kafka-0-10 % 2.2.0"
    ],
    "customImports" : null,
    "customArgs" : null,
    "customSparkConf" : null,
    "customVars" : null
  },
  "cells" : [
    {
      "metadata" : {
        "id" : "6E2995E02B244E978E1327B7A60484F0"
      },
      "cell_type" : "markdown",
      "source" : "# Structured Streaming - Kafka Example\nThis example ports our IoT data flow from Kafka to Parquet in a Structured Streaming version.  \n\nThe intention of this example is to explore the main aspects of the Structured Streaming API.\nWe will: \n - use the Kafka `source` to consume the `sensor-raw` topic.\n - implement the application logic using the Dataset API\n - use a file `sink` to store the data into a _Parquet_ file.\n \n \nThis example lets us compare and contrast the Structured Streaming approach with the Spark Streaming implementation that we already know."
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "3B783C2DA5A9409E85DF2CE7F061AECB"
      },
      "cell_type" : "code",
      "source" : [
        "val sourceTopic = \"sensor-raw\"\n",
        "val targetTopic = \"sensor-parsed\"\n",
        "val workDir = \"/tmp\"\n",
        "val referenceFile = \"sensor-records.parquet\"\n",
        "val kafkaBootstrapServer = \"172.17.0.2:9092\""
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "sourceTopic: String = sensor-raw\ntargetTopic: String = sensor-parsed\nworkDir: String = /tmp\nreferenceFile: String = sensor-records.parquet\nkafkaBootstrapServer: String = 172.17.0.2:9092\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 1,
          "time" : "Took: 0.947s, at 2017-11-28 23:11"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "3225F1A3939642B087F1BE6A37EB9D03"
      },
      "cell_type" : "code",
      "source" : [
        "val rawData = sparkSession.readStream\n",
        "      .format(\"kafka\")\n",
        "      .option(\"kafka.bootstrap.servers\", kafkaBootstrapServer)\n",
        "      .option(\"subscribe\", sourceTopic)\n",
        "      .option(\"enable.auto.commit\", true)\n",
        "      .option(\"group.id\", \"sensor-data-consumer\")\n",
        "      .option(\"startingOffsets\", \"latest\")\n",
        "      .load()"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "rawData: org.apache.spark.sql.DataFrame = [key: binary, value: binary ... 5 more fields]\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 2,
          "time" : "Took: 1.041s, at 2017-11-28 23:11"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "497CEEFAB7DF40F884CC7A8139C3DA5F"
      },
      "cell_type" : "code",
      "source" : [
        "rawData.isStreaming"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "res3: Boolean = true\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : "true"
          },
          "output_type" : "execute_result",
          "execution_count" : 3,
          "time" : "Took: 0.853s, at 2017-11-28 23:11"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "A74BF086DCC240168F21E57797088678"
      },
      "cell_type" : "code",
      "source" : [
        "rawData.printSchema()"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "root\n |-- key: binary (nullable = true)\n |-- value: binary (nullable = true)\n |-- topic: string (nullable = true)\n |-- partition: integer (nullable = true)\n |-- offset: long (nullable = true)\n |-- timestamp: timestamp (nullable = true)\n |-- timestampType: integer (nullable = true)\n\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 4,
          "time" : "Took: 0.911s, at 2017-11-28 23:11"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "F2782E9257024A819A1ADAAC2EFB1238"
      },
      "cell_type" : "markdown",
      "source" : "## We need to declare the schema of the data in the stream.\nthis is a handy way to do so."
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "A39D7FB1A9AC496F8DFC7502EB0A4C29"
      },
      "cell_type" : "code",
      "source" : [
        "case class SensorData(id: String, ts: Long, temp: Double, hum: Double)"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "defined class SensorData\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 5,
          "time" : "Took: 0.682s, at 2017-11-28 23:12"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "89E72AB850BC4AE7812D0236B3F51CED"
      },
      "cell_type" : "code",
      "source" : [
        "import org.apache.spark.sql.Encoders\n",
        "val schema = Encoders.product[SensorData].schema"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "import org.apache.spark.sql.Encoders\nschema: org.apache.spark.sql.types.StructType = StructType(StructField(id,StringType,true), StructField(ts,LongType,false), StructField(temp,DoubleType,false), StructField(hum,DoubleType,false))\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 6,
          "time" : "Took: 1.170s, at 2017-11-28 23:12"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "6E729EE3495E4AA88FC9E347BDEE3210"
      },
      "cell_type" : "code",
      "source" : [
        "val rawValues = rawData.selectExpr(\"CAST(value AS STRING)\").as[String]\n",
        "val jsonValues = rawValues.select(from_json($\"value\", schema) as \"record\")\n",
        "val sensorData = jsonValues.select(\"record.*\").as[SensorData]"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "rawValues: org.apache.spark.sql.Dataset[String] = [value: string]\njsonValues: org.apache.spark.sql.DataFrame = [record: struct<id: string, ts: bigint ... 2 more fields>]\nsensorData: org.apache.spark.sql.Dataset[SensorData] = [id: string, ts: bigint ... 2 more fields]\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 8,
          "time" : "Took: 1.430s, at 2017-11-28 23:22"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "CD174F6E3EF1475AA51899B5931B7415"
      },
      "cell_type" : "markdown",
      "source" : "## Load the reference data from a parquet fileÂ¶\nWe also cache the data to keep it in memory and improve the performance of our steaming application"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "0314D4CF7E88448EB2A5BDBED5839282"
      },
      "cell_type" : "code",
      "source" : [
        "val sensorRef = sparkSession.read.parquet(s\"$workDir/$referenceFile\")\n",
        "sensorRef.cache()"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "org.apache.spark.sql.AnalysisException: Path does not exist: file:/tmp/learningsparkstreaming/sensor-records.parquet;\n  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:360)\n  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$14.apply(DataSource.scala:348)\n  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n  at scala.collection.immutable.List.foreach(List.scala:381)\n  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)\n  at scala.collection.immutable.List.flatMap(List.scala:344)\n  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:348)\n  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:178)\n  at org.apache.spark.sql.DataFrameReader.parquet(DataFrameReader.scala:559)\n  at org.apache.spark.sql.DataFrameReader.parquet(DataFrameReader.scala:543)\n  ... 63 elided\n"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "18B7AD28DC70429186B5B0152415B55B"
      },
      "cell_type" : "markdown",
      "source" : "# Join the incoming Streaming data with the reference table "
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "6BFEA7F7BD8C4A6486D2CB08D8DAA87A"
      },
      "cell_type" : "code",
      "source" : [
        "val sensorWithInfo = sensorRef.join(iotData, Seq(\"sensorId\"), \"inner\")"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "<console>:77: error: not found: value sensorRef\n       val sensorWithInfo = sensorRef.join(iotData, Seq(\"sensorId\"), \"inner\")\n                            ^\n"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "B428CC561FC44119BAC17074566B0DC3"
      },
      "cell_type" : "code",
      "source" : [
        "val knownSensors = sensorWithInfo.withColumn(\"dnvalue\", $\"value\"*($\"maxRange\"-$\"minRange\")+$\"minRange\")\n",
        "  .drop(\"value\", \"maxRange\", \"minRange\")"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "<console>:68: error: not found: value sensorWithInfo\n       val knownSensors = sensorWithInfo.withColumn(\"dnvalue\", $\"value\"*($\"maxRange\"-$\"minRange\")+$\"minRange\")\n                          ^\n"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "967DA9CD00034B93A9F9077ACCABBF69"
      },
      "cell_type" : "code",
      "source" : [
        "val knownSensorsQuery = knownSensors.writeStream\n",
        "  .outputMode(\"append\")\n",
        "  .format(\"parquet\")\n",
        "  .option(\"path\", \"/tmp/learning-spark-streaming/stst-known_sensors\")\n",
        "  .option(\"checkpointLocation\", \"/tmp/checkpoint\")\n",
        "  .start()"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "<console>:68: error: not found: value knownSensors\n       val knownSensorsQuery = knownSensors.writeStream\n                               ^\n"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "presentation" : {
          "tabs_state" : "{\n  \"tab_id\": \"#tab1120185255-0\"\n}",
          "pivot_chart_state" : "{\n  \"hiddenAttributes\": [],\n  \"menuLimit\": 200,\n  \"cols\": [],\n  \"rows\": [],\n  \"vals\": [],\n  \"exclusions\": {},\n  \"inclusions\": {},\n  \"unusedAttrsVertical\": 85,\n  \"autoSortUnusedAttrs\": false,\n  \"inclusionsInfo\": {},\n  \"aggregatorName\": \"Count\",\n  \"rendererName\": \"Table\"\n}"
        },
        "id" : "C60D42C6AA7C43108AF52A4EEA7B407E"
      },
      "cell_type" : "code",
      "source" : [
        "\n",
        "knownSensorsQuery.recentProgress"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "<console>:71: error: not found: value knownSensorsQuery\n       knownSensorsQuery.recentProgress\n       ^\n"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "A8292D947D7E4A889B416F5C2BB158C7"
      },
      "cell_type" : "code",
      "source" : [
        ""
      ],
      "outputs" : [
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 20,
          "time" : "Took: 0.716s, at 2017-08-10 17:22"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "414735A902F34CDE84D1C3642D512973"
      },
      "cell_type" : "code",
      "source" : [
        "sensorData.writeStream\n",
        "  .queryName(\"visualization\")    // this query name will be the table name\n",
        "  .outputMode(\"append\")\n",
        "  .format(\"memory\")\n",
        "  .start()"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "res11: org.apache.spark.sql.streaming.StreamingQuery = org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@131140da\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : "org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@131140da"
          },
          "output_type" : "execute_result",
          "execution_count" : 9,
          "time" : "Took: 1.039s, at 2017-11-28 23:22"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "AA5DF0B0AD6D4EF093A9879DB10A106E"
      },
      "cell_type" : "code",
      "source" : [
        "val sample = Seq((System.currentTimeMillis, 0.1))\n",
        "\n",
        "val chart = CustomPlotlyChart(sample,\n",
        "                  layout=s\"{title: 'sensor data sample'}\",\n",
        "                  dataOptions=\"\"\"{type: 'line'}\"\"\",\n",
        "                  dataSources=\"{x: '_1', y: '_2'}\")"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "sample: Seq[(Long, Double)] = List((1511907794533,0.1))\nchart: notebook.front.widgets.charts.CustomPlotlyChart[Seq[(Long, Double)]] = <CustomPlotlyChart widget>\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 12,
          "time" : "Took: 0.907s, at 2017-11-28 23:23"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "96F04B890C7E461D867607E185400136"
      },
      "cell_type" : "code",
      "source" : [
        "chart"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "res17: notebook.front.widgets.charts.CustomPlotlyChart[Seq[(Long, Double)]] = <CustomPlotlyChart widget>\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : "<div>\n      <script data-this=\"{&quot;dataId&quot;:&quot;anon70001f2737a71dc35a9c4d25b1b01fd8&quot;,&quot;dataInit&quot;:[{&quot;_1&quot;:1511907794533,&quot;_2&quot;:0.1}],&quot;genId&quot;:&quot;1455280183&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/playground','../javascripts/notebook/magic/customPlotlyChart'], \n      function(playground, _magiccustomPlotlyChart) {\n        // data ==> data-this (in observable.js's scopedEval) ==> this in JS => { dataId, dataInit, ... }\n        // this ==> scope (in observable.js's scopedEval) ==> this.parentElement ==> div.container below (toHtml)\n\n        playground.call(data,\n                        this\n                        ,\n                        {\n    \"f\": _magiccustomPlotlyChart,\n    \"o\": {\"js\":\"var layout = {title: 'sensor data sample'}; var dataSources={x: '_1', y: '_2'}; var dataOptions = {type: 'line'}; var extraOptions = {}\",\"headers\":[\"_1\",\"_2\"],\"height\":400}\n  }\n  \n                        \n                        \n                      );\n      }\n    );/*]]>*/</script>\n    <div>\n      <span class=\"chart-total-item-count\"><p data-bind=\"text: value\"><script data-this=\"{&quot;valueId&quot;:&quot;anon109d97e7847c5ac173dd9e3ae88c7d4d&quot;,&quot;initialValue&quot;:&quot;1&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/\nreq(\n['observable', 'knockout'],\nfunction (O, ko) {\n  ko.applyBindings({\n      value: O.makeObservable(valueId, initialValue)\n    },\n    this\n  );\n});\n        /*]]>*/</script></p> entries total</span>\n      <span class=\"chart-sampling-warning\"><p data-bind=\"text: value\"><script data-this=\"{&quot;valueId&quot;:&quot;anon51fe74c41c91094d9444271bc5857e03&quot;,&quot;initialValue&quot;:&quot;&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/\nreq(\n['observable', 'knockout'],\nfunction (O, ko) {\n  ko.applyBindings({\n      value: O.makeObservable(valueId, initialValue)\n    },\n    this\n  );\n});\n        /*]]>*/</script></p></span>\n      <div>\n      </div>\n    </div></div>"
          },
          "output_type" : "execute_result",
          "execution_count" : 13,
          "time" : "Took: 0.974s, at 2017-11-28 23:23"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "0FE35A21951B4B2D8C58FD6F03820CD9"
      },
      "cell_type" : "code",
      "source" : [
        "val dataSample = sparkSession.sql(\"select * from visualization where ts > 1511908486082\")\n",
        "  "
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "dataSample: org.apache.spark.sql.DataFrame = [id: string, ts: bigint ... 2 more fields]\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 26,
          "time" : "Took: 0.570s, at 2017-11-28 23:34"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "DF508C9DFB4C446D8219998789F7AB21"
      },
      "cell_type" : "code",
      "source" : [
        "dataSample"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "res38: org.apache.spark.sql.DataFrame = [id: string, ts: bigint ... 2 more fields]\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : "<div class=\"df-canvas\">\n      <script data-this=\"{&quot;dataId&quot;:&quot;anon8e26d6989eac7807fe89423ccf9b7713&quot;,&quot;partitionIndexId&quot;:&quot;anonb4b686dea530cd5baaa1b68a8849d15b&quot;,&quot;numPartitions&quot;:17,&quot;dfSchema&quot;:{&quot;type&quot;:&quot;struct&quot;,&quot;fields&quot;:[{&quot;name&quot;:&quot;id&quot;,&quot;type&quot;:&quot;string&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;ts&quot;,&quot;type&quot;:&quot;long&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;temp&quot;,&quot;type&quot;:&quot;double&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;hum&quot;,&quot;type&quot;:&quot;double&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}}]}}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/dataframe','../javascripts/notebook/consoleDir'], \n      function(dataframe, extension) {\n        dataframe.call(data, this, extension);\n      }\n    );/*]]>*/</script>\n      <link rel=\"stylesheet\" href=\"/assets/stylesheets/ipython/css/dataframe.css\" type=\"text/css\"/>\n    </div>"
          },
          "output_type" : "execute_result",
          "execution_count" : 27,
          "time" : "Took: 0.878s, at 2017-11-28 23:34"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "7EE18736A04E4354BD4F2B92E8DC90CC"
      },
      "cell_type" : "code",
      "source" : [
        "\n",
        "res14.lastProgress"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "res37: org.apache.spark.sql.streaming.StreamingQueryProgress =\n{\n  \"id\" : \"6193c21b-4b8b-4141-b545-0b288e01ca3c\",\n  \"runId\" : \"45717cf3-7e65-4837-955c-5e6e8506dd25\",\n  \"name\" : \"visualization\",\n  \"timestamp\" : \"2017-11-28T21:58:43.088Z\",\n  \"numInputRows\" : 4,\n  \"inputRowsPerSecond\" : 56.33802816901409,\n  \"processedRowsPerSecond\" : 57.97101449275362,\n  \"durationMs\" : {\n    \"addBatch\" : 41,\n    \"getBatch\" : 5,\n    \"getOffset\" : 1,\n    \"queryPlanning\" : 2,\n    \"triggerExecution\" : 69,\n    \"walCommit\" : 19\n  },\n  \"stateOperators\" : [ ],\n  \"sources\" : [ {\n    \"description\" : \"KafkaSource[Subscribe[sensor-raw]]\",\n    \"startOffset\" : {\n      \"sensor-raw\" : {\n        \"0\" : 1100\n      }\n    },\n    \"endOffset\" : {\n      \"sensor-raw\" : {\n        \"0\" : 1104\n      }\n    },\n    \"numInputRows\" : 4,\n  ..."
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : "{\n  &quot;id&quot; : &quot;6193c21b-4b8b-4141-b545-0b288e01ca3c&quot;,\n  &quot;runId&quot; : &quot;45717cf3-7e65-4837-955c-5e6e8506dd25&quot;,\n  &quot;name&quot; : &quot;visualization&quot;,\n  &quot;timestamp&quot; : &quot;2017-11-28T21:58:43.088Z&quot;,\n  &quot;numInputRows&quot; : 4,\n  &quot;inputRowsPerSecond&quot; : 56.33802816901409,\n  &quot;processedRowsPerSecond&quot; : 57.97101449275362,\n  &quot;durationMs&quot; : {\n    &quot;addBatch&quot; : 41,\n    &quot;getBatch&quot; : 5,\n    &quot;getOffset&quot; : 1,\n    &quot;queryPlanning&quot; : 2,\n    &quot;triggerExecution&quot; : 69,\n    &quot;walCommit&quot; : 19\n  },\n  &quot;stateOperators&quot; : [ ],\n  &quot;sources&quot; : [ {\n    &quot;description&quot; : &quot;KafkaSource[Subscribe[sensor-raw]]&quot;,\n    &quot;startOffset&quot; : {\n      &quot;sensor-raw&quot; : {\n        &quot;0&quot; : 1100\n      }\n    },\n    &quot;endOffset&quot; : {\n      &quot;sensor-raw&quot; : {\n        &quot;0&quot; : 1104\n      }\n    },\n    &quot;numInputRows&quot; : 4,\n    &quot;inputRowsPerSecond&quot; : 56.33802816901409,\n    &quot;processedRowsPerSecond&quot; : 57.97101449275362\n  } ],\n  &quot;sink&quot; : {\n    &quot;description&quot; : &quot;MemorySink&quot;\n  }\n}"
          },
          "output_type" : "execute_result",
          "execution_count" : 28,
          "time" : "Took: 0.487s, at 2017-11-28 22:58"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "06AFEE5AE0764ECCB6F01239CF4267B9"
      },
      "cell_type" : "code",
      "source" : [
        ""
      ],
      "outputs" : [ ]
    }
  ],
  "nbformat" : 4
}